---
title: "Semantic-Based self-Critical Training for Question Generation"
collection: publications
permalink: /publication/2021-11-17-paper-2
excerpt: 'This paper is about building a language generation models to generate question which satisfy the standard of a semantic-based metric.'
date: 2021-11-17
venue: 'American Journal of Information Science and Technology'
paperurl: 'http://www.ajist.org/article/526/10.11648.j.ajist.20210504.12'
citation: 'Lo√Øc Kwate Dassi, Semantic-Based Self-Critical Training for Question Generation, American Journal of Information Science and Technology. Volume 5, Issue 4, December 2021 , pp. 93-97. doi: 10.11648/j.ajist.20210504.12.'
---

[Download paper here](https://lkwate.github.io/files/Semantic-based-question-generation.pdf)

Question generation is a conditioned language generation task that consists in generating a context-aware question given a context and the targeted answer. Train language modelling with a mere likelihood maximization has been widely used while suffering from exposure bias and the discordance between the training and the test metrics. In the way of addressing this issue, The presented work portrays a fully Transformer-based reinforcement learning generator-evaluation architecture for neural question generation. To edge the flexibility of the generation, a semantic-based reward score was externally infused during the training to drive the training of the language model. The global architecture is laid out in a generator-evaluator fashion optimized directly to n-gram and semantic-based metrics. Evaluation metrics for language modelling only based on n-gram overlapping do not consider semantic relations between reference and candidate sequences. To improve the evaluation step, a two-fold evaluation was carried out. On the one side, an n-gram overlapping evaluation using the BLEU score. On the other side, a semantic-based assessment using BERTScore and NUBIA. The results were corroborated by a binary human evaluation of the semantic relatedness of the generated question and the ground truth. The results obtained showed that use a semantic-based REINFORCE algorithm for the question generation syntactically reshapes the generated questions while preserving their underlying semantic meaning. Many downstream applications can be drawn from a successful question generation including the enlargement of question answering datasets, the improvement of conversational systems, the enhancement of autonomous educational assessment systems, and so forth.